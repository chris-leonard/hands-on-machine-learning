{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d374a242",
   "metadata": {},
   "source": [
    "# Chapter 2: End-to-End Machine Learning Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305504c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5a101",
   "metadata": {},
   "source": [
    "**Main Steps:**\n",
    "1. Big picture\n",
    "2. Get the data\n",
    "3. Discover and visualise\n",
    "4. Prepare data\n",
    "5. Select and train model\n",
    "6. Fine-tune model\n",
    "7. Present solution\n",
    "8. Launch, monitor, and maintain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373005f",
   "metadata": {},
   "source": [
    "## Look at the Big Picture <a name=\"bigpicture\"></a>\n",
    "\n",
    "**Goal:** use census data to predict median housing price per district.\n",
    "\n",
    "### Frame the Problem <a name=\"frameproblem\"></a>\n",
    "\n",
    "**Questions:**\n",
    "1. What is the end business objective?\n",
    "2. What is the current solution?\n",
    "    - Gives a reference for performance and insights on possible solutions\n",
    "3. Frame the problem\n",
    "    - Supervised, unsupervised, reinforcement etc.\n",
    "    - Problem type (regression, classification etc.)\n",
    "    - Batch learning or online learning?\n",
    "    \n",
    "### Select a Performance Measure <a name=\"performancemeasures\"></a>\n",
    "\n",
    "Common performance measures for regession problems are:\n",
    "- *Root Mean Square Error (RMSE):*\n",
    "\\begin{equation}\n",
    "    \\text{RMSE}(\\mathbf{X}, h) = \\sqrt{ \\frac{1}{m} \\sum_{i=1}^m \\left( h(\\mathbf{x}^{(i)}) - y^{(i)}\\right)^2 }\n",
    "\\end{equation}\n",
    "\n",
    "- *Mean Absolute Error (MAE):*\n",
    "\\begin{equation}\n",
    "    \\text{MAE}(\\mathbf{X}, h) = \\frac{1}{m} \\sum_{i=1}^m \\Big\\lvert h(\\mathbf{x}^{(i)}) - y^{(i)}\\Big\\rvert\n",
    "\\end{equation}\n",
    "\n",
    "- Other $l_k$ norms\n",
    "\n",
    "The higher $k$ the greater the impact of large values, so RMSE is more sensitive to outliers than MAE. RMSE is better if outliers are exponentially rare (like a bell curve), otherwise MAE may be better.\n",
    "\n",
    "### Check the Assumptions <a name=\"checkassumptions\"></a>\n",
    "\n",
    "Assumptions in the problem - e.g. are exact values necessary in a regression problem, or just categories?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ab93d4",
   "metadata": {},
   "source": [
    "## Get the Data <a name=\"getdata\"></a>\n",
    "\n",
    "### Create the Workspace <a name=\"createworkspace\"></a>\n",
    "\n",
    "Blah Blah\n",
    "\n",
    "### Download the Data <a name=\"downloaddata\"></a>\n",
    "\n",
    "- Good to have a function that downloads the data\n",
    "- Write a script that uses the function to fetch latest data\n",
    "- *Optional:* schedule a job to fetch latest data automatically at regular intervals\n",
    "- Also should write function to load data\n",
    "\n",
    "### Take a Quick Look at the Data Structure <a name=\"quicklook\"></a>\n",
    "\n",
    "- `df.head()`\n",
    "- `df.info()`\n",
    "    - Note missing values\n",
    "    - List data types: categorical (ordinal/numerical) or numerical (discrete/continuous/interval)\n",
    "- `df.describe()`\n",
    "- List different values for discrete data using `df.value_counts()`\n",
    "- Histograms of numerical data using `df.hist(bins=50, figsize=(20, 15))`\n",
    "\n",
    "### Create a Test Set <a name=\"testset\"></a>\n",
    "\n",
    "- **Data snooping bias:** Overfitting to the *test* set by looking at test set (even briefly)\n",
    "- `train_test_split` from Scikit-Learn splits data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716f0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Uniformly sampled data from 0 to 100\n",
    "data = pd.DataFrame(100 * np.random.random(50), columns=['cont'])\n",
    "\n",
    "# Split into 80/20 proportions\n",
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e858067",
   "metadata": {},
   "source": [
    "**Issue:**\n",
    "- Isn't reproducible: running it again results in different split\n",
    "- One solution: do this once and save\n",
    "- Another: set `random_state=42` to control shuffling and ensure reproducible output\n",
    "- But: neither of these work if you update the dataset. The textbook has a potential solution by splitting by hashed identifiers\n",
    "\n",
    "**Stratified Sampling:**\n",
    "- If dataset isn't large enough, random selection of test set can introduce sampling bias\n",
    "- Stratified sampling guarantees test set is representative of population by controlling for specific factors\n",
    "- Population is divided into *strata* and sample has same proportions in each stratum\n",
    "- Ex: controlling for gender\n",
    "- Use `StratifiedShuffleSplit` from Scikit-Learn\n",
    "- **Q:** How to decide what to control for? How many factors can you control for? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a245d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.447623</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.887668</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.919338</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.330967</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.656797</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78.043343</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.769441</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.791181</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41.079619</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>82.446540</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cont     cat\n",
       "0  63.447623  medium\n",
       "1  64.887668  medium\n",
       "2  86.919338    high\n",
       "3  32.330967     low\n",
       "4   4.656797     low\n",
       "5  78.043343    high\n",
       "6  19.769441     low\n",
       "7  36.791181  medium\n",
       "8  41.079619  medium\n",
       "9  82.446540    high"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uniformly sampled data from 0 to 100\n",
    "data = pd.DataFrame(100 * np.random.random(1000), columns=['cont'])\n",
    "\n",
    "# pd.cut to bin data - useful for turning continuous data into categorical (e.g. strata)\n",
    "# (Scikit-Learn also has Discretization functionality)\n",
    "data['cat'] = pd.cut(\n",
    "    data['cont'], \n",
    "    bins=[0, 33, 66, 100], \n",
    "    labels=['low', 'medium', 'high'], \n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bdec87fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.319</td>\n",
       "      <td>0.31875</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.335</td>\n",
       "      <td>0.33500</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>0.346</td>\n",
       "      <td>0.34625</td>\n",
       "      <td>0.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Overall    Train   Test\n",
       "low       0.319  0.31875  0.320\n",
       "medium    0.335  0.33500  0.335\n",
       "high      0.346  0.34625  0.345"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Initialise split object\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# This loop has only one iteration but syntax is necessary because of split class\n",
    "# 2nd arg indicates what to control for, 1st arg just gives n_samples so could just use np.zeros(n_samples)\n",
    "for train_index, test_index in split.split(data, data['cat']):\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "\n",
    "# Function to compare proportions in the different sets\n",
    "def cat_proportions(df):\n",
    "    return df['cat'].value_counts() / len(df)\n",
    "\n",
    "# DataFrame to store results\n",
    "compare_props = pd.DataFrame({\n",
    "    'Overall': cat_proportions(data),\n",
    "    'Train' : cat_proportions(train),\n",
    "    'Test': cat_proportions(test),\n",
    "}).sort_index()\n",
    "\n",
    "compare_props"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e203846f",
   "metadata": {},
   "source": [
    "## Discover and Visualise the Data to Gain Insights <a name=\"discoverandvisualise\"></a>\n",
    "\n",
    "- If training set is large, sample exploration set for speed\n",
    "- Copy training set to avoid 'damage'\n",
    "\n",
    "### Visualising Geographical Data <a name=\"geographicaldata\"></a>\n",
    "\n",
    "- Use `df.plot(kind='scatter', x='x_val', y='y_val')`\n",
    "- May need to play around to pick out patterns\n",
    "- Useful parameters to capture other dimensions:\n",
    "    - `alpha=0.1`: opacity of circles to help see high density\n",
    "    - `s=df['col']`: control radius of circles by column\n",
    "    - `c=df['col'], cmap=plt.get_cmap('jet')`: colour scale based on column\n",
    "- Use this generate ideas for features etc.\n",
    "- Repository has an example of plotting over a map\n",
    "\n",
    "### Looking for Correlations <a name=\"correlations\"></a>\n",
    "\n",
    "**Pearson's Correlation Coefficient:** Covariance scaled by product of standard deviations:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\rho_{X,Y} \n",
    "        = \\frac{\\text{cov}(X, Y)}{\\sigma_X \\sigma_Y}\n",
    "        = \\frac{\\text{E}\\left[(X-\\mu_X)(Y-\\mu_Y)\\right]}{\\sigma_X \\sigma_Y}\n",
    "\\end{equation}\n",
    "\n",
    "**Correlation Matrix:** \n",
    "- Matrix with $(X, Y)$ entry $\\rho_{X,Y}$\n",
    "- `df.corr()`\n",
    "- Note that this only measures linear correlations\n",
    "\n",
    "**Scatter Matrix:**\n",
    "- `from pandas.plotting import scatter_matrix`\n",
    "- Scatter plots of all combinations of attributes and histograms on diagonal\n",
    "- May be better to do subset of features\n",
    "\n",
    "### Experimenting with Attribute Combinations <a name=\"attributecombinations\"></a>\n",
    "\n",
    "- Try out different attribute combinations (e.g. ratios) and looking back at correlations.\n",
    "- At first this can be quick - you can go back and look for better ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309ab8b",
   "metadata": {},
   "source": [
    "# Prepare the Data for Machine Learning Algorithms <a name=\"prepareformachinelearning\"></a>\n",
    "\n",
    "You should write functions to prepare the data:\n",
    "- This makes it reproducible (you can even use it in a live system)\n",
    "- This allows you to build a library of functions for the future\n",
    "- Makes it easier to try different combinations of functions\n",
    "\n",
    "Separate predictors and targets - don't always want to apply same transformations to both\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "Generally need to resolve missing values either by:\n",
    "- Removing samples\n",
    "- Removing feature\n",
    "- 'Imputing' missing values (e.g. using the median)\n",
    "\n",
    "*Note:* Whatever you do will need to be replicated on the test set and in production\n",
    "\n",
    "**SimpleImputer**: Scikit-Learn class to fill missing values\n",
    "- `from sklearn.impute import SimpleImputer`\n",
    "- `strategy`: options are mean, median, most_frequent, or constant\n",
    "- For mean and median, data must be numeric\n",
    "- Good idea to impute for all features that may be missing values in production, even if not missing in training set\n",
    "\n",
    "Scikit-Learn also has (experimental) *multivariate* feature imputation, which fills values using other features, and nearest neighbours imputation.\n",
    "\n",
    "**Multiple Imputation:** In statistics it's common to perform to try multiple imputations and use cross-validation at the end of the pipeline to understand the consequences of different strategies.\n",
    "\n",
    "### Handling Text and Categorical Attributes <a name=\"handlingcategorical\"></a>\n",
    "\n",
    "ML algorithms generally need numbers so we need to convert categories to numerical form via *encoding*.\n",
    "\n",
    "**Ordinal Encoding:** Enumerate different categories\n",
    "- `from sklearn.preprocessing import OrdinalEncoder`\n",
    "- This implicitly gives an ordering and measure of similarity to the categories\n",
    "\n",
    "**One-hot Encoding:** Assigns each category a new binary feature\n",
    "- Or *dummy* encoding or *one-of-K* encoding\n",
    "- `from sklearn.preprocessing import OneHotEncoder`\n",
    "- Output is a SciPy *sparse matrix* which just holds position of '1' in each row - use `toarray()` to convert\n",
    "- Treats missing values as a separate category (Q: could you use mean imputer after encoding?)\n",
    "- To avoid colinearity, use `drop='first'` to encode in `n_categories - 1`. Use `drop=if_binary` to encode e.g. male/female as single binary\n",
    "\n",
    "One-hot encoding may be unwise for large number of categories (for performance reasons). Possible solution is to use proxy features (e.g. population and GDP in place of country code). Another is to use a low-dimensional embedding learned during training (see *representation learning*).\n",
    "\n",
    "### Custom Transformers  <a name=\"customtransformers\"></a>\n",
    "\n",
    "- You should turn custom data cleaning into transformers so they'll integrate with Scikit-Learn\n",
    "- Need a class with 3 method: `fit()` (returning `self`), `transform()`, and `fit_transform()`\n",
    "- Set `TransformerMixin` as a base class to get `fit_transform()` for free\n",
    "- Set `BaseEstimator` as a base class to get `get_params()` and `set_params()` methods (can't have `*args` and `*kwargs` in `__init__` constructor)\n",
    "- *Advice:* Add hyperparameters to 'gate' data preparation steps (e.g. adding a new feature) so you can turn them on and off\n",
    "\n",
    "### Feature Scaling <a name=\"featurescaling\"></a>\n",
    "\n",
    "- ML algorithms generally don't perform well when inputs have very different scales\n",
    "- Scaling output values is generally not required\n",
    "\n",
    "**Min-max Scaling:** Linear scaling to [0, 1] range\n",
    "- Also called *normalisation*\n",
    "- `from sklearn.preprocessing import MinMaxScaler`\n",
    "- Very sensitive to outliers\n",
    "- *Q:* Is it a problem that unseen data may not fit in the [0, 1] range?\n",
    "\n",
    "**Standardisation:** Linear scaling to 0 mean and unit variance\n",
    "- `from sklearn.preprocessing import StandardScaler`\n",
    "- Doesn't work for some ML algorithms which need inputs to be in range [0, 1]\n",
    "\n",
    "- Centring sparse data (e.g. dummy binary variables from categorical data) is inadvisable because this destroys the sparsity, but you can still do scaling (consider using `MaxAbsScaler`)\n",
    "- Scaling data with many outliers may not work very well - consider using `RobustScaler` instead\n",
    "\n",
    "### Transformation Pipelines <a name=\"pipelines\"></a>\n",
    "\n",
    "**Pipelines:** chain estimators into a composite estimator\n",
    "- `from sklearn.pipeline import Pipeline`\n",
    "- `make_pipeline` is a shorthand for constructing pipelines\n",
    "- Pipelines only transform observed data X, use `TransformedTargetRegresssor` to transform target y\n",
    "- All but last estimator must be transformers (they have `.fit_transform()` method)\n",
    "- Calling `.fit()` on pipeline does `fit_transform()` on all but last one which it calls `fit()`\n",
    "\n",
    "**ColumnTransformer:** allows you to apply different transformers to different columns\n",
    "- `from sklearn.compose import ColumnTransformer`\n",
    "- `make_column_transformer` is a shorthand\n",
    "- What happens to unlisted columns is determined by arg `remainder: {'drop', 'passthrough'}` or an estimator to be applied to them\n",
    "- The estimators that go in can themselves be pipelines\n",
    "- When outputs are mix of dense and sprase matrices, `ColumnTransformer` decides density of output based on ratio of dense/sparse in inputs\n",
    "- Use `from sklearn import set_config // set_config(display='diagram')` to show diagrams of composite estimators\n",
    "- `make_column_selector` is useful to select columns to go into `ColumnTransformer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd24c3a1",
   "metadata": {},
   "source": [
    "## Select and Train a Model <a name=\"selectandtrain\"></a>\n",
    "\n",
    "### Training and Evaluating on the Training Set <a name=\"evaluatingontrainingset\"></a>\n",
    "\n",
    "- A reasonable standard error metric is RMSE\n",
    "- I like to compare with the base error rate (for regression this is error if predicting using the mean)\n",
    "- Training error is a bad estimate of generalisation error because of overfitting\n",
    "\n",
    "### Better Evaluation Using Cross-Validation <a name=\"evaluatingusingcrossvalidation\"></a>\n",
    "\n",
    "**K-Fold Cross-Validation:** Partitions training set into $K$ *folds* and trains and calculates validation error leaving one fold out each time\n",
    "- Can use `cross_val_score` to just get one score, or `cross_validate` to use multiple metrics and return more info\n",
    "- *Note:* Scikit-learn cross-validation expects a *utility* function rather than a *cost* function, so error metrics (e.g. RMSE) need to be *negative* (e.g. `neg_root_mean_square_error`)\n",
    "- Cross-validation can be very slow becuase it needs to train the model many times\n",
    "- **Q:** How accurate are the mean and standard deviation of error scores as estimates or generalisation error/stdev? What is the relationship between this and number of folds?\n",
    "- There are other options than just splitting randomly into folds, e.g. `StratifiedKFold` - c.f. `StratifiedShuffleSplit`\n",
    "- *Leave-One-Out Cross-Validation:* Take n_folds = n_samples. From Scikit-learn: \"As a general rule, most authors, and empirical evidence, suggest that 5- or 10- fold cross validation should be preferred to LOO.\"\n",
    "- It may be necessary to shuffle data before cross-validating if order isn't already random\n",
    "\n",
    "**Note:** Try out a few different models from different categories before spending too much time tweaking hyperparameters. *The goal is to shortlist a few (2-5) promising models.*\n",
    "\n",
    "**joblib:** Python library to avoid having to compute the same thing twice\n",
    "- Use `joblib.dump(my_model, 'my_model.pkl')` to save models, parameters, hyperparameters, cv-scores, and predictions so you don't have to do them twice\n",
    "- Then use `my_model_loaded = joblib.load('my_model.pkl)` to get it back instantly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364363fc",
   "metadata": {},
   "source": [
    "## Fine-Tune Your Model <a name=\"finetune\"></a>\n",
    "\n",
    "### Grid Search <a name=\"gridsearch\"></a>\n",
    "\n",
    "**GridSearchCV:** Perform (cross-)validation across a specified grid of hyperparameters\n",
    "- `param_grid` can take multiple dictionaries of parameters. Within each dictionary it does every combination of parameters\n",
    "- This can be very slow, particularly combined with cross-validation\n",
    "- A good choice for parameters is approximate powers of 3: 3, 10, 30, 100,...\n",
    "\n",
    "**RandomizedSearchCV:** Cross-validation with a fixed number of samples of hyperparameters from specified distributions.\n",
    "- `param_distributions` specifies distributions of each parameter using `scipy.stats`\n",
    "- Advantages:\n",
    "    - Full control over number of iterations\n",
    "    - Given 1,000 iterations, each parameter takes 1,000 values, not just the few you specified in grid search (so including irrelevant hyperparameters doesn't reduce efficacy of search)\n",
    "\n",
    "**Other options:**\n",
    "- Some models can fit data with a variety of hyperparameter values at once (in particular regularisation paths for linear models). Scikit-Learn has estimators that incorporate this (e.g. `RidgeCV`)\n",
    "- Some models have closed-form formulae for the optimal regularisation parameter based on information criteria (AIC or BIC), e.g. `LassoLarsIC`\n",
    "\n",
    "**Additional guidance:**\n",
    "- Specify multiple metrics for evaluation (*why?*)\n",
    "- Search over parameters of composite estimators (e.g. pipelines)\n",
    "\n",
    "### Ensemble Methods <a name=\"ensemblemethods\"></a>\n",
    "\n",
    "Combine models that perform best.\n",
    "\n",
    "### Analyse the Best Models and Their Errors <a name=\"analysebestmodels\"></a>\n",
    "\n",
    "For example, use insights to improve feature set (some models have dedicated methods for this), or look at specific errors.\n",
    "\n",
    "### Evaluate Your System on the Test Set <a name=\"evaluateontestset\"></a>\n",
    "\n",
    "- This is easier if you have a transformer that incorporates the data processing and the estimator\n",
    "- If you did a lot of hyperparameter tuning then test performance may be worse than CV error\n",
    "\n",
    "The text has an example of constructing a confidence interval around the test error. I am sceptical about this. It seems to assume that the squared error of the estimator is distributed normally (is this reasonable?). Then the difference between the sample mean (of the squared errors) and the true mean, divided by the standard error is distributed according to Student's t-distribution. This then yields a confidence interval for the true mean. I think I need to read ESL to understand this properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8fe1e0",
   "metadata": {},
   "source": [
    "## Other Terminology\n",
    "\n",
    "**Data Pipeline**: a sequence of data processing components\n",
    "- Components run asynchronously and outputs are stored in data stores between components\n",
    "- Components are self-contained so if one component fails, downstream components can continue using last output\n",
    "- Monitoring is important so failing components can be caught and fixed\n",
    "\n",
    "**Map Reduce:** programming paradigm of using parallel, distributed algorithims to process data\n",
    "- To allow a group of (memory independent) computers to process data that is too much for a single processor\n",
    "\n",
    "**Duck Typing:** Programming paradigm - \"if it walks like a duck and it quacks like a duck, then it must be a duck\"\n",
    "\n",
    "**Ensemble Learning:** Building a model on top of many other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9350d0",
   "metadata": {},
   "source": [
    "## Code Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b47f41e",
   "metadata": {},
   "source": [
    "### OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "570ef672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Operation system dependent functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d3c72b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/christopherleonard/P/hands-on-machine-learning\n"
     ]
    }
   ],
   "source": [
    "PATH = '/Users/christopherleonard'\n",
    "\n",
    "# To combine path names into one complete path\n",
    "# Note that it adds the necessary slash\n",
    "ML_PATH = os.path.join(PATH, 'P/hands-on-machine-learning')\n",
    "print(ML_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fbc9810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if specified path is an existing directory\n",
    "os.path.isdir(ML_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c41f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create specified directory\n",
    "# Will return error if already exists\n",
    "TEST_PATH = os.path.join(ML_PATH, 'chapter-2/test')\n",
    "os.mkdir(TEST_PATH)\n",
    "\n",
    "# Also works with relative directory\n",
    "os.mkdir('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359df432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
