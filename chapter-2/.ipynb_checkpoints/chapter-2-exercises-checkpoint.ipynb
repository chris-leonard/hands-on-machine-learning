{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42daa555",
   "metadata": {},
   "source": [
    "# Chapter 2 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c573d265",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Preparation](#preparation)\n",
    "- [Exercise 1](#ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea32883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydata stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.model_selection import StratifiedShuffleSplit # To split into train/test set\n",
    "from sklearn.base import BaseEstimator, TransformerMixin # To create custom transformers\n",
    "from sklearn.impute import SimpleImputer # To handle missing values\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder # Feature scaling and dealing with categorical\n",
    "from sklearn.pipeline import Pipeline # Pipelines to chain estimators\n",
    "from sklearn.compose import ColumnTransformer # To apply different transformers to different columns\n",
    "from sklearn.metrics import mean_squared_error # Metrics\n",
    "\n",
    "# Models\n",
    "from sklearn.svm import SVR # Support vector machine regressor\n",
    "\n",
    "# Cross validation/hyperparameter tuning\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Display HTML representation of composite estimators\n",
    "from sklearn import set_config \n",
    "set_config(display='diagram')  \n",
    "\n",
    "# Miscellaneous packages\n",
    "import os # For OS dependent functionality\n",
    "from time import perf_counter # To measure performance\n",
    "import joblib # To save arbitrary Python objects (e.g. models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cee7f",
   "metadata": {},
   "source": [
    "## Preparation <a name=\"preparation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc8e6a",
   "metadata": {},
   "source": [
    "These exercises are based on the housing example project so require some set up.\n",
    "\n",
    "Begin by loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a066d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7747f7",
   "metadata": {},
   "source": [
    "Now create a test set using stratified sampling on median income as a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7379d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn median income from continuous to categorical variable\n",
    "housing[\"income_cat\"] = pd.cut(\n",
    "    housing[\"median_income\"],\n",
    "    bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "    labels=[1, 2, 3, 4, 5]\n",
    ")\n",
    "\n",
    "# Create split\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "    \n",
    "# Remove new categorical variable\n",
    "for df in [strat_train_set, strat_test_set]:\n",
    "    df.drop('income_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180179e",
   "metadata": {},
   "source": [
    "Now some data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1783b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a clean copy of training set and separate into inputs and outputs\n",
    "housing = strat_train_set.drop('median_house_value', axis=1)\n",
    "housing_labels = strat_train_set['median_house_value'].copy()\n",
    "\n",
    "# Split training set into categorical and numerical attributes\n",
    "housing_cat = housing[['ocean_proximity']]\n",
    "housing_num = housing.drop('ocean_proximity', axis=1)\n",
    "\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "num_attribs = list(housing_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de819273",
   "metadata": {},
   "source": [
    "We want a custom transformer to add additional columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53ac53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column indices since you need to input and output numpy arrays\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, add_bedrooms_per_room=True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "        \n",
    "    def fit(self, X, y=None):       \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):   \n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        \n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            \n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        \n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ba9fc6",
   "metadata": {},
   "source": [
    "Now create pipeline for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3dd9176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for numerical inputs\n",
    "estimators = [\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")), # (name, estimator) pairs\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler())\n",
    "]\n",
    "num_pipeline = Pipeline(estimators)\n",
    "\n",
    "# Combine numerical and categorical pipelines\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "\n",
    "# Prepare data\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5b752a",
   "metadata": {},
   "source": [
    "## Exercise 1 <a name=\"ex1\"></a>\n",
    "\n",
    "Try a Support Vector Machine regressor (`sklearn.svm.SVR`) with various hyperparameters, such as `kernel=\"linear\"` (with various values for the `C` hyperparameter) or `kernel=\"rbf\"` (with various values for the `C` and `gamma` hyperparameters). Don't worry about what these hyperparameters mean for now. How does the best `SVR` predictor perform?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f1988",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d9c68",
   "metadata": {},
   "source": [
    "Start with all hyperparameters taking default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a1272ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regressor RMSE: 118581\n"
     ]
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr.fit(housing_prepared, housing_labels)\n",
    "\n",
    "svr_predictions = svr.predict(housing_prepared)\n",
    "svr_rmse = mean_squared_error(svr_predictions, housing_labels, squared=False)\n",
    "print('Support Vector Regressor RMSE: {:0.0f}'.format(svr_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a135c809",
   "metadata": {},
   "source": [
    "The base error rate was 115700 so we are definitely underfitting.\n",
    "\n",
    "Let's try again with a grid search. I've saved the result of the grid search as a `.pkl` file as it takes a while to run. If such a file exists, the following function will just load it rather than rerunning the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10c826b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_FOLDER = 'models'\n",
    "\n",
    "def perform_svr_grid_search(models_folder=MODELS_FOLDER):\n",
    "    '''\n",
    "    Loads grid_search from 'models_folder/svr-grid-search.pkl' if it exists,\n",
    "    otherwise performs SVR grid search and saves to this path. Note that \n",
    "    running the grid search takes about 15 minutes.\n",
    "    '''\n",
    "    grid_search_path = os.path.join(models_folder, 'svr-grid-search.pkl')\n",
    "    \n",
    "    if os.path.isfile(grid_search_path):\n",
    "        grid_search = joblib.load(grid_search_path)\n",
    "        print('Grid search loaded from ' + grid_search_path)\n",
    "        return grid_search\n",
    "    \n",
    "    else:       \n",
    "        # Initialise model\n",
    "        svr = SVR()\n",
    "\n",
    "        # Set params to try\n",
    "        param_grid = [\n",
    "            {'kernel': ['linear'], 'C': [0.1, 0.3, 1, 3, 10]},\n",
    "            {'kernel': ['rbf'], 'C': [0.3, 1, 3], 'gamma': ['scale', 'auto']}\n",
    "        ]\n",
    "\n",
    "        # Initialise grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            svr,\n",
    "            param_grid,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            cv=5,\n",
    "            return_train_score=True,\n",
    "            refit=True\n",
    "        )\n",
    "\n",
    "        # Perform search\n",
    "        start_time = perf_counter()\n",
    "        grid_search.fit(housing_prepared, housing_labels)\n",
    "        end_time = perf_counter()\n",
    "        print('Grid search run time: {:0.1f} seconds'.format(end_time - start_time))\n",
    "\n",
    "        # Save output\n",
    "        joblib.dump(grid_search, grid_search_path)\n",
    "        \n",
    "        return grid_search\n",
    "\n",
    "\n",
    "grid_search = perform_svr_grid_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11cb3ec",
   "metadata": {},
   "source": [
    "Show a summary of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d1d31d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>kernel_param</th>\n",
       "      <th>C_param</th>\n",
       "      <th>gamma_param</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84641</td>\n",
       "      <td>84614</td>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102386</td>\n",
       "      <td>102369</td>\n",
       "      <td>linear</td>\n",
       "      <td>3.0</td>\n",
       "      <td>scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112560</td>\n",
       "      <td>112548</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116890</td>\n",
       "      <td>116885</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118052</td>\n",
       "      <td>118049</td>\n",
       "      <td>rbf</td>\n",
       "      <td>3.0</td>\n",
       "      <td>scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>118064</td>\n",
       "      <td>118060</td>\n",
       "      <td>rbf</td>\n",
       "      <td>3.0</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>118237</td>\n",
       "      <td>118234</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>118620</td>\n",
       "      <td>118617</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>118623</td>\n",
       "      <td>118620</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>118821</td>\n",
       "      <td>118820</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.3</td>\n",
       "      <td>scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>118822</td>\n",
       "      <td>118820</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.3</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  mean_train_score kernel_param  C_param gamma_param\n",
       "0             84641             84614       linear     10.0       scale\n",
       "1            102386            102369       linear      3.0       scale\n",
       "2            112560            112548       linear      1.0       scale\n",
       "3            116890            116885       linear      0.3       scale\n",
       "4            118052            118049          rbf      3.0       scale\n",
       "5            118064            118060          rbf      3.0        auto\n",
       "6            118237            118234       linear      0.1       scale\n",
       "7            118620            118617          rbf      1.0       scale\n",
       "8            118623            118620          rbf      1.0        auto\n",
       "9            118821            118820          rbf      0.3       scale\n",
       "10           118822            118820          rbf      0.3        auto"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is just a utility function\n",
    "def get_param_from_dict(dict, param_name, param_default=None):\n",
    "    'Use with .apply() to get series of parameter values from series of params dicts'\n",
    "    if dict.get(param_name) is not None:\n",
    "        return dict.get(param_name)\n",
    "    else:\n",
    "        return param_default\n",
    "\n",
    "\n",
    "# Get results\n",
    "cv_res = grid_search.cv_results_\n",
    "cv_res_summary = pd.DataFrame(\n",
    "    {\n",
    "        'params' : cv_res['params'], \n",
    "        'mean_test_score' : cv_res['mean_test_score'],\n",
    "        'mean_train_score' : cv_res['mean_train_score'],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Make test scores positive and round them\n",
    "cv_res_summary[['mean_test_score', 'mean_train_score']] = -cv_res_summary[['mean_test_score', 'mean_train_score']].astype(int)\n",
    "\n",
    "# Split params column into individual parameter values\n",
    "param_defaults = {\n",
    "    'kernel': 'rbf',\n",
    "    'C': 1.0,\n",
    "    'gamma': 'scale'\n",
    "}\n",
    "\n",
    "for key, value in param_defaults.items():\n",
    "    col_name = key + '_param'\n",
    "    cv_res_summary[col_name] = cv_res_summary['params'].apply(\n",
    "        lambda dict: get_param_from_dict(dict, param_name=key, param_default=value)\n",
    "    )    \n",
    "\n",
    "\n",
    "# Clean up\n",
    "cv_res_summary.drop(columns='params', inplace=True)\n",
    "cv_res_summary = cv_res_summary.sort_values('mean_test_score', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Show results\n",
    "cv_res_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7881d973",
   "metadata": {},
   "source": [
    "The models underperform both the ordinary least squares and random forest regressors, but since the maximum value of `C` yielded by far the lowest mean test score we can probably improve performance by tuning the hyperparameters. Indeed, since the test and train scores are so similar, we are probably underfitting the model. This fits with the fact that `C` is the regularisation parrameter and is inversely proportional to the strength of the regularisation: increasing `C` should reduce underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4c29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
